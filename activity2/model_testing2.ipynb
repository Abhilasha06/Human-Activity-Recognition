{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of the folder containing all the foreground binary images\n",
    "train_data='D:\\\\xy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 551/551 [00:02<00:00, 253.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#storing the image and label of train data\n",
    "\n",
    "def train_data_with_label():\n",
    "    train_images=[]\n",
    "    global ohl\n",
    "    for i in tqdm(os.listdir(train_data)):\n",
    "        path=os.path.join(train_data,i)\n",
    "        img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img=cv2.resize(img,(64,64))\n",
    "        label=path.split('+')[1]\n",
    "        if label=='wave1.jpg.jpg':\n",
    "            ohl=np.array([1,0,0])\n",
    "        if label=='wave2.jpg.jpg':\n",
    "            ohl=np.array([0,1,0])\n",
    "        if label=='bend.jpg.jpg':\n",
    "            ohl=np.array([0,0,1])\n",
    "        train_images.append([np.array(img),ohl])\n",
    "    shuffle(train_images)\n",
    "    return train_images\n",
    "\n",
    "training_images = train_data_with_label()\n",
    "\n",
    "tr_img_data = np.array([i[0] for i in training_images]).reshape(-1,64,64,1)\n",
    "tr_lbl_data = np.array([i[1] for i in training_images])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "551/551 [==============================] - ETA: 14s - loss: 10.3059 - acc: 0.310 - ETA: 11s - loss: 8.8173 - acc: 0.360 - ETA: 7s - loss: 8.7880 - acc: 0.3467 - ETA: 4s - loss: 8.7762 - acc: 0.352 - ETA: 1s - loss: 8.6233 - acc: 0.358 - 18s 33ms/step - loss: 8.3585 - acc: 0.3684\n",
      "Epoch 2/10\n",
      "551/551 [==============================] - ETA: 14s - loss: 6.6342 - acc: 0.40 - ETA: 11s - loss: 6.6061 - acc: 0.41 - ETA: 8s - loss: 6.4469 - acc: 0.4367 - ETA: 4s - loss: 6.1023 - acc: 0.462 - ETA: 1s - loss: 6.0116 - acc: 0.460 - 18s 32ms/step - loss: 5.8772 - acc: 0.4701\n",
      "Epoch 3/10\n",
      "551/551 [==============================] - ETA: 14s - loss: 4.3041 - acc: 0.52 - ETA: 10s - loss: 3.7412 - acc: 0.55 - ETA: 7s - loss: 3.8774 - acc: 0.5600 - ETA: 4s - loss: 3.5015 - acc: 0.572 - ETA: 1s - loss: 3.3361 - acc: 0.590 - 17s 31ms/step - loss: 3.2520 - acc: 0.5953\n",
      "Epoch 4/10\n",
      "551/551 [==============================] - ETA: 13s - loss: 1.6098 - acc: 0.69 - ETA: 10s - loss: 1.4442 - acc: 0.69 - ETA: 7s - loss: 1.1516 - acc: 0.7200 - ETA: 4s - loss: 1.1727 - acc: 0.720 - ETA: 1s - loss: 1.0640 - acc: 0.736 - 17s 31ms/step - loss: 1.0456 - acc: 0.7350\n",
      "Epoch 5/10\n",
      "551/551 [==============================] - ETA: 14s - loss: 0.4120 - acc: 0.85 - ETA: 11s - loss: 0.3770 - acc: 0.87 - ETA: 7s - loss: 0.4124 - acc: 0.8567 - ETA: 4s - loss: 0.4423 - acc: 0.847 - ETA: 1s - loss: 0.4468 - acc: 0.848 - 17s 31ms/step - loss: 0.4468 - acc: 0.8475\n",
      "Epoch 6/10\n",
      "551/551 [==============================] - ETA: 14s - loss: 0.2259 - acc: 0.89 - ETA: 10s - loss: 0.2177 - acc: 0.91 - ETA: 7s - loss: 0.2350 - acc: 0.9133 - ETA: 4s - loss: 0.2797 - acc: 0.902 - ETA: 1s - loss: 0.2588 - acc: 0.910 - 17s 31ms/step - loss: 0.2611 - acc: 0.9111\n",
      "Epoch 7/10\n",
      "551/551 [==============================] - ETA: 12s - loss: 0.0783 - acc: 0.99 - ETA: 9s - loss: 0.1329 - acc: 0.9600 - ETA: 7s - loss: 0.1353 - acc: 0.960 - ETA: 4s - loss: 0.1615 - acc: 0.952 - ETA: 1s - loss: 0.1620 - acc: 0.954 - 17s 31ms/step - loss: 0.1618 - acc: 0.9546\n",
      "Epoch 8/10\n",
      "551/551 [==============================] - ETA: 14s - loss: 0.1253 - acc: 0.98 - ETA: 11s - loss: 0.1084 - acc: 0.98 - ETA: 8s - loss: 0.1446 - acc: 0.9667 - ETA: 4s - loss: 0.1391 - acc: 0.970 - ETA: 1s - loss: 0.1262 - acc: 0.974 - 17s 32ms/step - loss: 0.1293 - acc: 0.9728\n",
      "Epoch 9/10\n",
      "551/551 [==============================] - ETA: 13s - loss: 0.1578 - acc: 0.95 - ETA: 10s - loss: 0.1594 - acc: 0.95 - ETA: 7s - loss: 0.1434 - acc: 0.9567 - ETA: 4s - loss: 0.1286 - acc: 0.957 - ETA: 1s - loss: 0.1376 - acc: 0.958 - 18s 32ms/step - loss: 0.1380 - acc: 0.9583\n",
      "Epoch 10/10\n",
      "551/551 [==============================] - ETA: 13s - loss: 0.1626 - acc: 0.97 - ETA: 10s - loss: 0.1302 - acc: 0.97 - ETA: 7s - loss: 0.1241 - acc: 0.9733 - ETA: 4s - loss: 0.1080 - acc: 0.977 - ETA: 1s - loss: 0.0958 - acc: 0.980 - 17s 31ms/step - loss: 0.0976 - acc: 0.9800\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 183,973\n",
      "Trainable params: 183,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#cnn model\n",
    "\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=[64,64,1]))\n",
    "model.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5,padding='same'))         \n",
    "model.add(Conv2D(filters=50,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5,padding='same'))         \n",
    "model.add(Conv2D(filters=80,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5,padding='same'))          \n",
    "model.add(Dropout(0.25)) #avoid overfitting\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(3,activation='softmax')) #3 labels\n",
    "optimizer=Adam(lr=1e-3)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x=tr_img_data,y=tr_lbl_data,epochs=10,batch_size=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of the video to be tested\n",
    "path=\"D:\\\\wave1\\\\daria_wave1.avi\"\n",
    "cam = cv2.VideoCapture(path) \n",
    "\n",
    "#path of the background of the above video\n",
    "img=cv2.imread(\"D:\\\\hj.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "img=cv2.resize(img,(64,64))\n",
    "  \n",
    "while(True): \n",
    "              \n",
    "        ret,frame = cam.read() \n",
    " \n",
    "        if ret==True:     \n",
    "            \n",
    "            cv2.imwrite(\"D:\\\\frame.jpg\",frame)\n",
    "            image2 = cv2.imread(\"D:\\\\frame.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "            image2=cv2.resize(image2,(64,64))\n",
    "            imgg=cv2.subtract(img,image2)\n",
    "            cv2.imwrite(\"D:\\\\hjg.jpg\",imgg)\n",
    "        \n",
    "            blur = cv2.GaussianBlur(imgg,(3,3),0)\n",
    "            ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            cv2.imwrite(\"D:\\\\hji.jpg\",th3)\n",
    "            data=th3.reshape(1,64,64,1)\n",
    "            \n",
    "            #feeding the processed image to model for prediction\n",
    "            model_out=model.predict([data]) \n",
    "            \n",
    "            if np.argmax(model_out)==0:\n",
    "                label=\"1HandWave\"\n",
    "            if np.argmax(model_out)==1:\n",
    "                label=\"2HandWave\"\n",
    "            if np.argmax(model_out)==2:\n",
    "                label=\"bending\"\n",
    "                \n",
    "            #displaying each frame\n",
    "            cv2.putText(frame,label,(0,25),cv2.FONT_HERSHEY_DUPLEX,1,(0,0,255))\n",
    "            cv2.imshow(\"frame\",frame)\n",
    " \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                 break\n",
    "        else:\n",
    "            break\n",
    "       \n",
    "  \n",
    "# Release all space and windows once done \n",
    "cam.release() \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing a live video\n",
    "#for first few seconds the backround should be left empty\n",
    "cam = cv2.VideoCapture(0) \n",
    "c=0\n",
    "  \n",
    "while(cam.isOpened()): \n",
    "      \n",
    "    # reading from frame \n",
    "    \n",
    "        ret,frame = cam.read() \n",
    " \n",
    "        if ret==True: \n",
    "            \n",
    "            #saving the image of background only\n",
    "            if c==0:\n",
    "                cv2.imwrite(\"D:\\\\hj.jpg\",frame)\n",
    "                img=cv2.imread(\"D:\\\\hj.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "            img=cv2.resize(img,(64,64))\n",
    "            cv2.imwrite(\"D:\\\\frame.jpg\",frame)\n",
    "            image2 = cv2.imread(\"D:\\\\frame.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "            image2=cv2.resize(image2,(64,64))\n",
    "            \n",
    "            #subtracting the background from the frame\n",
    "            imgg=cv2.subtract(img,image2)\n",
    "        \n",
    "            blur = cv2.GaussianBlur(imgg,(3,3),0)\n",
    "            ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            cv2.imwrite(\"D:\\\\hji.jpg\",th3)\n",
    "            data=th3.reshape(1,64,64,1)\n",
    "            model_out=model.predict([data]) \n",
    "            \n",
    "            if np.argmax(model_out)==0:\n",
    "                label=\"1HandWave\"\n",
    "            if np.argmax(model_out)==1:\n",
    "                label=\"2HandWave\"\n",
    "            if np.argmax(model_out)==2:\n",
    "                label=\"Bending\"\n",
    "                \n",
    "            cv2.putText(frame,label,(0,30),cv2.FONT_HERSHEY_DUPLEX,1,(0,0,255))\n",
    "            cv2.imshow(\"frame\",frame)\n",
    "            c+=1\n",
    " \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                 break\n",
    "        else:\n",
    "            break\n",
    "       \n",
    "  \n",
    "# Release all space and windows once done \n",
    "cam.release() \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
